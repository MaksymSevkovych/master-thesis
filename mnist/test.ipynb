{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import VariationalAutoencoder\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed(autoencoder, r0=(-5, 10), r1=(-10, 5), n=12):\n",
    "    w = 28\n",
    "    img = np.zeros((n * w, n * w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(DEVICE)\n",
    "            x_hat = autoencoder.decoder(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to(DEVICE).detach().numpy()\n",
    "            img[(n - 1 - i) * w : (n - 1 - i + 1) * w, j * w : (j + 1) * w] = x_hat\n",
    "    plt.imshow(img, extent=[*r0, *r1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(autoencoder, optimizer, data_loader, num_epochs=10):\n",
    "    outputs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for img, _ in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            recon = autoencoder(img)\n",
    "            loss = ((img - recon) ** 2).sum() + autoencoder.encoder.kl\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch:{epoch+1}, Loss:{loss.item():.4f}\")\n",
    "        outputs.append((epoch, img, recon))\n",
    "    return outputs, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "latent_dims = 2\n",
    "\n",
    "# data\n",
    "transform = transforms.ToTensor()\n",
    "data = datasets.MNIST(root=\"./data\", download=True, train=True, transform=transform)\n",
    "data_loader = DataLoader(dataset=data, batch_size=64, shuffle=True)\n",
    "\n",
    "vae = VariationalAutoencoder(latent_dims)\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:1611.7825\n",
      "Epoch:2, Loss:1515.8401\n",
      "Epoch:3, Loss:1380.7217\n",
      "Epoch:4, Loss:1362.4689\n",
      "Epoch:5, Loss:1380.8900\n",
      "Epoch:6, Loss:1377.2250\n",
      "Epoch:7, Loss:1399.5312\n",
      "Epoch:8, Loss:1307.5063\n",
      "Epoch:9, Loss:1398.9788\n",
      "Epoch:10, Loss:1320.8795\n",
      "Epoch:11, Loss:1421.5096\n",
      "Epoch:12, Loss:1285.0626\n",
      "Epoch:13, Loss:1303.9221\n",
      "Epoch:14, Loss:1514.8007\n",
      "Epoch:15, Loss:1148.7078\n",
      "Epoch:16, Loss:1323.2950\n",
      "Epoch:17, Loss:1285.6498\n",
      "Epoch:18, Loss:1242.9644\n",
      "Epoch:19, Loss:1379.0179\n",
      "Epoch:20, Loss:1254.9299\n"
     ]
    }
   ],
   "source": [
    "outputs, vae = train(\n",
    "        vae, optimizer=optimizer, data_loader=data_loader, num_epochs=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructed(vae, (-3, 3), (-3, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
