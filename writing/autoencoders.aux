\relax
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Autoencoders}{13}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Conceptional ideas}{13}{section.2.1}\protected@file@percent }
\newlabel{def_encoder}{{2.1.1}{13}{}{theorem.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces An autoencoding neural network with input and output $x, y\in \R  ^5$. The five hidden layers have dimensions $4$, $3$, $2$, $3$ and $4$ respectively. Hence, the bottleneck dimension is $2$ in this example. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }}{14}{figure.caption.3}\protected@file@percent }
\newlabel{autoencoder}{{2.1}{14}{An autoencoding neural network with input and output $x, y\in \R ^5$. The five hidden layers have dimensions $4$, $3$, $2$, $3$ and $4$ respectively. Hence, the bottleneck dimension is $2$ in this example. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces An encoding neural network with input $x\in \R  ^5$ and output $y \in \R  ^2$. The two hidden layers have dimensions $4$ and $3$. Hence, the encoder reduces the data dimensionality from $5$ to $2$ dimension. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }}{14}{figure.caption.4}\protected@file@percent }
\newlabel{img_encoder}{{2.2}{14}{An encoding neural network with input $x\in \R ^5$ and output $y \in \R ^2$. The two hidden layers have dimensions $4$ and $3$. Hence, the encoder reduces the data dimensionality from $5$ to $2$ dimension. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }{figure.caption.4}{}}
\newlabel{def_decoder}{{2.1.2}{14}{}{theorem.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A decoding neural network with input $x\in \R  ^2$ and output $y \in \R  ^5$. The two hidden layers have dimensions $3$ and $4$. Hence, the decoder expands the data dimensionality from $2$ to $5$ dimensions. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }}{15}{figure.caption.5}\protected@file@percent }
\newlabel{img_decoder}{{2.3}{15}{A decoding neural network with input $x\in \R ^2$ and output $y \in \R ^5$. The two hidden layers have dimensions $3$ and $4$. Hence, the decoder expands the data dimensionality from $2$ to $5$ dimensions. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }{figure.caption.5}{}}
\newlabel{lemma:composition_of_nns}{{2.1.3}{15}{}{theorem.2.1.3}{}}
\newlabel{nn_1}{{2.1}{15}{Conceptional ideas}{equation.2.1.1}{}}
\newlabel{nn_2}{{2.2}{15}{Conceptional ideas}{equation.2.1.2}{}}
\newlabel{nn_comp}{{2.3}{16}{Conceptional ideas}{equation.2.1.3}{}}
\citation{foster2022generative}
\newlabel{def_autoencoder}{{2.1.5}{17}{}{theorem.2.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Training of autoencoders}{17}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Applications}{18}{section.2.3}\protected@file@percent }
\newlabel{def_linear_encoder}{{2.3.1}{18}{}{theorem.2.3.1}{}}
\newlabel{def_linear_decoder}{{2.3.2}{18}{}{theorem.2.3.2}{}}
\newlabel{def:mnist}{{2.3.4}{18}{}{theorem.2.3.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Linear autoencoder\relax }}{19}{algorithm.1}\protected@file@percent }
\newlabel{alg:linAE}{{1}{19}{Linear autoencoder\relax }{algorithm.1}{}}
\@setckpt{autoencoders}{
\setcounter{page}{20}
\setcounter{equation}{3}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{11}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{theorem}{4}
}
