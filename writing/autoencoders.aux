\relax
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Autoencoders}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Mathematical formulation of autoencoders}{6}{section.2.1}\protected@file@percent }
\newlabel{def_encoder}{{2.1.1}{6}{}{theorem.2.1.1}{}}
\newlabel{def_decoder}{{2.1.2}{6}{}{theorem.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces An autoencoder neural network with input and output $x, y\in \R  ^5$. The five hidden layers have dimensions $4$, $3$, $2$, $3$ and $4$ respectively. Hence, the bottleneck dimension is $2$ in this example. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }}{7}{figure.caption.3}\protected@file@percent }
\newlabel{autoencoder}{{2.1}{7}{An autoencoder neural network with input and output $x, y\in \R ^5$. The five hidden layers have dimensions $4$, $3$, $2$, $3$ and $4$ respectively. Hence, the bottleneck dimension is $2$ in this example. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces An encoder neural network with input $x\in \R  ^5$ and output $y \in \R  ^2$. The two hidden layers have dimensions $4$ and $3$. Hence, the encoder reduces the data dimensionality from $5$ to $2$ dimension. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{img_encoder}{{2.2}{7}{An encoder neural network with input $x\in \R ^5$ and output $y \in \R ^2$. The two hidden layers have dimensions $4$ and $3$. Hence, the encoder reduces the data dimensionality from $5$ to $2$ dimension. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A decoder neural network with input $x\in \R  ^2$ and output $y \in \R  ^5$. The two hidden layers have dimensions $3$ and $4$. Hence, the decoder expands the data dimensionality from $2$ to $5$ dimensions. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{img_decoder}{{2.3}{8}{A decoder neural network with input $x\in \R ^2$ and output $y \in \R ^5$. The two hidden layers have dimensions $3$ and $4$. Hence, the decoder expands the data dimensionality from $2$ to $5$ dimensions. The graphic was generated with http://alexlenail.me/NN-SVG/index.html\relax }{figure.caption.5}{}}
\@setckpt{autoencoders}{
\setcounter{page}{9}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{1}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{theorem}{2}
}
